---
title: '论文报告2018-2019学年上学期'
date: 2019-03-12
permalink: /posts/2019/03/blog-post-2/
tags:
  - deep learning
  - introduction
---

### Bayesian deep convolutional encoder–decoder networks for surrogate modeling and uncertainty quantification
- 作者 YinhaoZhu, NicholasZabaras
- 来源 Journal ofComputationalPhysics366(2018)415–447
- 时间 2018
#### 论文亮点
BNN 把神经网络的参数看做是随机变量，而不是定值，为了解决数据不足导致的认知不确定性。
模型最后的输出不仅仅是方程的解的值，还有方程的解的分布与方差
BNN模型可以用很少的数据量训练一个很复杂的模型。是其他的深度学习模型做不到的。
BNN本身就具有防止过拟合的效果。有很强的鲁棒性
#### 论文使用到的方法
BNN将网络中的每一个参数都看做是一个随机变量，并且在训练过程中不断调整参数的分布。
BNN的更新要使用变分推断进行
##### 变分推断
training inputs:$\mathbf { X } = \left\{ \mathbf { x } _ { 1 } , \ldots , \mathbf { x } _ { N } \right\}$
corresponding outputs$\mathbf { Y } = \left\{ \mathbf { y } _ { 1 } , \ldots , \mathbf { y } _ { N } \right\}$
找到参数w使得$\mathbf { y } = \mathbf { f } ^ { \omega } ( \mathbf { x } )$
先验信息:$p(\omega)$
分类问题下softmax 后的概率
$p ( y = d | \mathrm { x } , \omega ) = \frac { \exp \left( f _ { d } ^ { \omega } ( \mathrm { x } ) \right) } { \sum _ { d ^ { \prime } } \exp \left( f _ { d ^ { \prime } } ^ { \omega } ( \mathrm { x } ) \right) }$
或者Gaussian likelihood for regression
$p ( \mathbf { y } | \mathbf { x } , \boldsymbol { \omega } ) = \mathcal { N } \left( \mathbf { y } ; \mathbf { f } ^ { \omega } ( \mathbf { x } ) , \tau ^ { - 1 } I \right)$
with model precision $τ$ . This can be seen as corrupting the model output with observation noise with variance $τ^{−1}$.
使用贝叶斯公式
$p ( \boldsymbol { \omega } | \mathbf { X } , \mathbf { Y } ) = \frac { p ( \mathbf { Y } | \mathbf { X } , \boldsymbol { \omega } ) p ( \boldsymbol { \omega } ) } { p ( \mathbf { Y } | \mathbf { X } ) }$
$p ( \mathbf { Y } | \mathbf { X } , \boldsymbol { \omega })$可以算出， $p ( \boldsymbol { \omega } )$是先验分布。

Inference process:
给定一个新的输入点$x^*$
$p \left( \mathbf { y } ^ { * } | \mathbf { x } ^ { * } , \mathbf { X } , \mathbf { Y } \right) = \int p \left( \mathbf { y } ^ { * } | \mathbf { x } ^ { * } , \boldsymbol { \omega } \right) p ( \boldsymbol { \omega } | \mathbf { X } , \mathbf { Y } ) \mathrm { d } \omega$
normaliser or model evidence:
$p ( \mathbf { Y } | \mathbf { X } ) = \int p ( \mathbf { Y } | \mathbf { X } , \boldsymbol { \omega } ) p ( \boldsymbol { \omega } ) \mathrm { d } \boldsymbol { \omega }$
marginal likelihood
大多数情况下$ p ( \mathbf { Y } | \mathbf { X } ) $是没有解析解的，所以要用到变分推断
找到一个简单的分布$q _ { \theta } ( \boldsymbol { \omega } )$与所要求的分布尽量的接近。
$\mathrm { KL } \left( q _ { \theta } ( \omega ) \| p ( \omega | \mathbf { X } , \mathbf { Y } ) \right) = \int q _ { \theta } ( \omega ) \log \frac { q _ { \theta } ( \boldsymbol { \omega } ) } { p ( \boldsymbol { \omega } | \mathbf { X } , \mathbf { Y } ) } \mathrm { d } \boldsymbol { \omega }$
这里定义$q _ { \theta } ( \boldsymbol { \omega } )$ 是关于$p ( \boldsymbol { \omega } | \mathbf { X } , \mathbf { Y } )$完全连续的.
对于事件A，$p ( A | \mathbf { X } , \mathbf { Y } ) = 0$ implies $q _ { \theta } ( A ) = 0 $
设$q _ { \theta } ^ { * } ( \omega )$是目标函数的最优解。
这样就可以用$q _ { \theta } ^ { * } ( \omega )$代替$p ( \boldsymbol { \omega } | \mathbf { X } , \mathbf { Y } )$
$p \left( \mathbf { y } ^ { * } | \mathbf { x } ^ { * } , \mathbf { X } , \mathbf { Y } \right) \approx \int p \left( \mathbf { y } ^ { * } | \mathbf { x } ^ { * } , \omega \right) q _ { \theta } ^ { * } ( \boldsymbol { \omega } ) \mathrm { d } \omega = : q _ { \theta } ^ { * } \left( \mathbf { y } ^ { * } | \mathbf { x } ^ { * } \right)$
问题可以通过计算转换为:
$K L ( Q \| P ) = \int Q ( Z ) \log \frac { Q ( Z ) } { P ( Z | X ) } d Z$
$= - \int Q ( Z ) \log \frac { P ( Z | X ) } { Q ( Z ) } d Z$
$= - \int Q ( Z ) \log \frac { P ( Z , X ) } { Q ( Z ) P ( X ) } d Z$
$= \int Q ( Z ) [ \log Q ( Z ) + \log P ( X ) ] d Z - \int Q ( Z ) \log P ( Z , X ) d Z$
$=\int Q(Z) \log P ( X )dZ + \int Q ( Z ) \log Q ( Z ) d Z - \int Q ( Z ) \log P ( Z , X ) d Z$
所以问题换位最大化evidence lower bound (ELBO):
$\mathcal { L } _ { \mathrm { VI } } ( \theta ) : = \int q _ { \theta } ( \boldsymbol { \omega } ) \log p ( \mathbf { Y } | \mathbf { X } , \boldsymbol { \omega } ) \mathrm { d } \boldsymbol { \omega } - \mathrm { KL } \left( q _ { \theta } ( \boldsymbol { \omega } ) \| p ( \boldsymbol { \omega } ) \right) \leq \log p ( \mathbf { Y } | \mathbf { X } ) = \log$ evidence
最大化第一项(expected log lokelihood) 即为让$q _ { \theta } ( \boldsymbol { \omega } )$更好的解释数据
最小化第二项(prior KL)即为让$q _ { \theta } ( \boldsymbol { \omega } )$跟先验分布更接近。
This acts as an “Occam razor” term and penalises complex distributions$q _ { \theta } ( \boldsymbol { \omega } )$
保持了贝叶斯模型的好处，即拟合了数据，又用最简单的方法来
变分推断把积分计算变成了优化过程(求导)。
与深度学习的优化过程相比，这里优化的是一个分布，而不是点估计。
Note that optimisation in the deep learning sense can be recovered by setting the approximating distribution as a delta
##### SVGD
SVGD是在变分推断的基础上，与SGD结合产生的算法，在更新BNN上效果很好。与其他的算法相比有
1在数据量大时表现很好，2很容易用于复杂的模型中，且不用改变模型原本的架构。3使用起来很方便，不需要知道原理也可以使用。
![Alt text](./1547699242244.png)
